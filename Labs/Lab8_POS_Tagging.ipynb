{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para Lingüistas\n",
    "\n",
    "Notebook 8: POS Tagging\n",
    "\n",
    "Alejandro Ariza\n",
    "\n",
    "Universitat de Barcelona 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook veremos como realizar etiquetado POS usando NLTK.\n",
    "\n",
    "Usaremos diferentes etiquetadores y veremos la importancia de seleccionar un buen corpus de entrenamiento.\n",
    "\n",
    "También aprenderemos más acerca de funciones y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar los paquetes importantes para hoy\n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todos los recursos necesarios para hoy\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "# Importar numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importar codecs\n",
    "import codecs\n",
    "\n",
    "# Importar etiquetadores\n",
    "from nltk import DefaultTagger, AffixTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk import ClassifierBasedPOSTagger\n",
    "\n",
    "# Importar el corpus brown\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones avanzadas\n",
    "\n",
    "# Antes de continuar con el etiquetado POS, observermos el comportamiento de una función muy simple\n",
    "\n",
    "var_1 = \"Boo\"\n",
    "var_2 = \"Hoo\"\n",
    "var_3 = \"DooDoo\"\n",
    "\n",
    "def my_simple_function(atr_1, atr_2, atr_3=\"ignórame\"):\n",
    "    \n",
    "    print(\"Mi atr_1 es:\" + str(atr_1))\n",
    "    print(\"Mi atr_2 es:\" + str(atr_2))\n",
    "    print(\"Mi atr_3 es:\" + str(atr_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos lo que hace\n",
    "my_simple_function(var_1, var_2, var_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué pasa si cambiamos el orden?\n",
    "# Como podéis ver, la función asigna valores a las variables de entrada basándose en su posición\n",
    "my_simple_function(var_3, var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué pasa si no añadimos valor para el tercer argumento de entrada?\n",
    "my_simple_function(var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué pasa si no añadimos valor para el segundo argumento?\n",
    "my_simple_function(var_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué pasa si le decimos explícitamente qué es cada cosa?\n",
    "my_simple_function(atr_3=var_1, atr_1=var_2, atr_2=var_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetado POS en Python\n",
    "\n",
    "En esta clase, veremos diferentes formas de etiquetar automáticamente un corpus con su POS\n",
    "\n",
    "Nos centraremos en los etiquetadores basados en n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtened una lista de categorías del corpus brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguid la versión tokenizada y etiquetada de la categoría \"news\"\n",
    "brown_twords = brown.tagged_words(categories='news')\n",
    "\n",
    "# Conseguid la versión que, además, tiene la segmentación de las frases\n",
    "brown_tsents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimid las 5 primeras palabras\n",
    "print(\"\\nLas primeras 5 palabras en la versión tokenizada y etiquetada son:\")\n",
    "print(brown_twords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimid las dos primeras frases\n",
    "print(\"\\nLas primeras 2 frases en la versión con frases segmentadas son:\")\n",
    "print(brown_tsents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguid el conjunto de todas las etiquetas que aparecen en el corpus brown\n",
    "brown_tags = set([tag for (token,tag) in brown_twords])\n",
    "print(\"\\nEl conjunto de etiquetas en el corpus brown es:\")\n",
    "print(brown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguid el conjunto de todas las etiquetas que existen en la versión \"universal\"\n",
    "brown_utwords = brown.tagged_words(categories='news',tagset='universal')\n",
    "universal_tags = set([tag for (token,tag) in brown_utwords])\n",
    "print(\"\\nEl conjunto de etiquetas universales es:\")\n",
    "print(universal_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos y evaluaremos diferentes etiquetadores:\n",
    "\n",
    "- default\n",
    "- affix\n",
    "- unigram\n",
    "- bigram\n",
    "- trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetador por defecto\n",
    "\n",
    "# Obtened la versión segmentada y tokenizada de \"news\"\n",
    "# Esta es la versión no etiquetada que vamos a etiquetar\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# Obtened una lista de todas las etiquetas en el corpus\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "\n",
    "# Obtened la etiqueta más frecuente en el corpus\n",
    "most_frequent_tag = nltk.FreqDist(tags).max()\n",
    "\n",
    "# Imprimid la etiqueta más frecuente:\n",
    "print(most_frequent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurad un etiquetador por defecto\n",
    "# El etiquetador por defecto asigna la misma etiqueta por defecto a todos los tokens en el corpus\n",
    "# Lo configuraremos para que anote la etiqueta más frecuente\n",
    "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
    "\n",
    "my_sent = \"the quick brown fox jumped over the lazy dog\".split()\n",
    "print(\"La frase etiquetada con el etiquetador por defecto:\")\n",
    "print(default_tagger.tag(my_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluad el etiquetador por defecto en el corpus:\n",
    "print(\"La precisión del etiquetador por defecto en el corpus brown es:\")\n",
    "print(round(default_tagger.evaluate(brown_tsents),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el resto de etiquetadores, dividiremos el corpus en train y test:\n",
    "test_corpus = brown_tsents[:1000]\n",
    "train_corpus = brown_tsents[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena el etiquetador affix\n",
    "affix_tagger = AffixTagger(train_corpus)\n",
    "\n",
    "# Etiqueta el corpus\n",
    "affix_sents = affix_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Imprime la primera frase y la precisión\n",
    "print(\"\\nLa primera frase etiquetada con el etiquetador affix es:\")\n",
    "print(affix_sents[0])\n",
    "print(\"\\nLa precisión del etiquetador affix en el corpus es:\")\n",
    "print(round(affix_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "unigram_tagger = UnigramTagger(train_corpus) \n",
    "\n",
    "# Etiquetado\n",
    "uni_sents = unigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Visualización de resultados\n",
    "print(\"\\nLa primera frase etiquetada con el etiquetador basado en unigramas es:\")\n",
    "print(uni_sents[0])\n",
    "print(\"\\nLa precisión del etiquetador basado en unigramas en el corpus es:\")\n",
    "print(round(unigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "bigram_tagger = BigramTagger(train_corpus)\n",
    "\n",
    "# Etiquetado\n",
    "bi_sents = bigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Visualización de resultados\n",
    "print(\"\\nLa primera frase etiquetada con el etiquetador basado en bigramas es:\")\n",
    "print(bi_sents[0])\n",
    "print(\"\\nLa precisión del etiquetador basado en bigramas en el corpus es:\")\n",
    "print(round(bigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "trigram_tagger = TrigramTagger(train_corpus)\n",
    "\n",
    "# Etiquetado\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Visualización de resultados\n",
    "print(\"\\nLa primera frase etiquetada con el etiquetador basado en trigramas es:\")\n",
    "print(tri_sents[0])\n",
    "print(\"\\nLa precisión del etiquetador basado en trigramas en el corpus es:\")\n",
    "print(round(trigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "bigram_tagger_backoff = BigramTagger(train_corpus,backoff=unigram_tagger)\n",
    "\n",
    "# Etiquetado\n",
    "bi_sents_bo = bigram_tagger_backoff.tag_sents(brown_sents)\n",
    "\n",
    "\n",
    "# Visualización de resultados\n",
    "print(\"\\nLa primera frase etiquetada con el etiquetador basado en bigramas con backoff es:\")\n",
    "print(bi_sents_bo[0])\n",
    "print(\"\\nLa precisión del etiquetador basado en bigramas con backoff en el corpus es:\")\n",
    "print(round(bigram_tagger_backoff.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 1\n",
    "# Entrenar y evaluar en el mismo corpus en vez de usar particiones separadas\n",
    "# ¿Cuál es el resultado?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 2\n",
    "# Crear una secuencia de etiquetadores a modo backoff:\n",
    "# trigram -> bigram -> unigram -> affix -> default\n",
    "# Evaluar el etiquetador resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 3\n",
    "# Intentar cross-domain tagging:\n",
    "# Entrenar usando el corpus \"news\" y evaluar en \"science_fiction\"\n",
    "# Comparar los resultados con un corpus entrenado y evaluado en el mismo dominio (science_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 4\n",
    "# Importante del conjunto de etiquetas\n",
    "# Re-ejecutar las tareas 2 y 3 usando el etiquetado universal del corpus\n",
    "# Comparar las diferencias entre el etiquetado \"universal\" y el etiquetado completo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
